# @package _global_

training:
  start: 1000
  batch_size: 512
  learning_rate: 7.911253284662961e-05
reinforcement:
  discount: 0.9725055228173732
  target_temperature: -0.9458887469954789
  polyak_factor: 0.9814272369304672
imitation:
  trajectories: 5
  discriminator:
    hidden_size: 32
    depth: 2
    activation: relu
    input_dropout: 0.10172850778326392
    dropout: 0.5678929754532874
  pretraining:
    iterations: 67080
  learning_rate: 0.00025526777456514536
  weight_decay: 7.0671607460826635
  quantile_cutoff: 0.9085663554072381
