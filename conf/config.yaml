defaults:
  - hydra/sweeper: ax
  - algorithm: PPO #AIRL
  - environment: hopper # Check environment/hopper.yaml for PPO hyperparameters
seed: 0
#steps: 100000
#discount: 0.99
#trace_decay: 0.95
#ppo_clip: 0.2
#ppo_epochs: 4
#value_loss_coeff: 0.5
#entropy_loss_coeff: 0.5
learning_rate: 0.001
#batch_size: 1024
evaluation_interval: 1000
evaluation_episodes: 50
save_trajectories: false
imitation: ${algorithm.imitation}
state_only: false
absorbing: false
imitation_epochs: 5
imitation_batch_size: 128
imitation_replay_size: 4
r1_reg_coeff: 1.0
pos_class_prior: 0.5
nonnegative_margin: 0.0
render: false
# PPO param from Stable baseline zoo

# ax sweep setting
hydra:
  run:
    dir: ./outputs/${env_type}_${algorithm.imitation}
  sweep:
    dir: ./outputs/sweeper_${env_type}_${algorithm.imitation}
  sweeper:
    #ax configuration. Same across all algorithms
    ax_config:
      max_trials: 20

      experiment:
        minimize: false

      early_stop:
        max_epochs_without_improvement: 5

      is_noisy: true

      params:
        batch_size:
          type: choice
          values: [ 512, 1024, 2048 ]
        learning_rate:
          type: range
          bounds: [ 0.0001, 0.001 ]
