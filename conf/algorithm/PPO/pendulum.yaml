# @package _global_
env_type: pendulum
env_name: pendulum-v0

imitation: PPO
#IL param
# PPO param to be optimized
batch_size: 4096
ppo_epochs: 20
agent_learning_rate: !!float 3e-3
entropy_loss_coeff: 0.001
