# @package _global_
env_type: pendulum
env_name: pendulum-v0

imitation: PPO
# PPO param
batch_size: 512
entropy_loss_coeff: 0.0
ppo_epochs: 10
ppo_learning_rate: !!float 3e-4
