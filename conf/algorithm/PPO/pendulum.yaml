# @package _global_
env_type: pendulum
env_name: pendulum-v0

imitation: PPO
# PPO hyperparameters
batch_size: 4096
agent_learning_rate: 0.0003
ppo_epochs: 10
entropy_loss_coeff: 0.01
