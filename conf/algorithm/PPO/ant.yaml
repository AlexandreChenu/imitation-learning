# @package _global_
env_type: ant
env_name: ant-bullet-medium-v0

imitation: PPO
# PPO param from rl-baseline3-zoo this one contains old naming commented out
steps: 2000000
batch_size: 512
discount: 0.99
trace_decay: 0.9
ppo_epochs: 10
entropy_loss_coeff: 0.0
max_grad_norm: 0.5
value_loss_coeff: 0.5
ppo_learning_rate: !!float 3e-5
ppo_clip: 0.25
log_std_init: -1 # -2?
hidden_size: 256

hydra:
  sweeper:
    #ax configuration. Same across all algorithms
    ax_config:
      max_trials: 20

      experiment:
        minimize: false

      early_stop:
        max_epochs_without_improvement: 5

      is_noisy: true

      params:
        batch_size:
          type: choice
          values: [ 256, 512, 1024, 2048 ]
        ppo_learning_rate:
          type: choice
          values: [ 0.00003, 0.0003 ]
        ppo_epochs:
          type: choice
          values: [5, 10, 20]
